{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b827c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "irrelevant_const = \"IRRELEVANT\"\n",
    "\n",
    "sign_subtitle_json_file_root = \"../extractedbdhandspeakskeletons/skeleton_subtitle_jsons\"\n",
    "# video_embeddings_root = \"../extractedbdhandspeakskeletons/video_embeddings\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(sign_subtitle_json_file_root) if isfile(join(sign_subtitle_json_file_root, f))]\n",
    "\n",
    "def generate_sequence_id(line):\n",
    "    p = re.compile('[a-zA-Z0-9\\-]')\n",
    "    return \"\".join(p.findall(line))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "keys_of_skeleton = []\n",
    "properties_of_consideration = [{\n",
    "    'name': 'pose_keypoints_2d', 'count': 25\n",
    "}, {\n",
    "    'name': 'face_keypoints_2d', 'count': 70\n",
    "}, {\n",
    "    'name': 'hand_left_keypoints_2d', 'count': 21\n",
    "}, {\n",
    "    'name': 'hand_right_keypoints_2d', 'count': 21\n",
    "}]\n",
    "\n",
    "total_body_keypoint_count = 0\n",
    "for property in properties_of_consideration:\n",
    "    property_name = \"_\".join(property['name'].split('_')[:-2])\n",
    "    for i in range(property['count']):\n",
    "        keys_of_skeleton.append(f\"{ property_name }_{i}_x\")\n",
    "        keys_of_skeleton.append(f\"{ property_name }_{i}_y\")\n",
    "\n",
    "train_set_videos, not_train_set_videos = train_test_split(onlyfiles, test_size=0.1, random_state=42)\n",
    "test_set_videos, validation_set_videos = train_test_split(not_train_set_videos, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee57fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set_videos))\n",
    "print(len(test_set_videos))\n",
    "print(len(validation_set_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f08c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_array(list_of_videos):\n",
    "    final_array = []\n",
    "    for json_file_name in tqdm(list_of_videos):\n",
    "        json_file_object = open(f\"{sign_subtitle_json_file_root}/{json_file_name}\", encoding='utf-8')\n",
    "    \n",
    "        json_dict = json.load(json_file_object)\n",
    "\n",
    "        # video_embedding_pickle_file_path = f\"{video_embeddings_root}/{json_file_name.split('.')[0]}.mp4.pickle\"\n",
    "        # with open(video_embedding_pickle_file_path, 'rb') as f:\n",
    "        #     video_embeddings = pickle.load(f)\n",
    "        \n",
    "        for single_sentence_data in json_dict['skeleton_data']:\n",
    "            sequence_id = f\"{json_dict['video_name']}%%{single_sentence_data['english']}%%{single_sentence_data['start_time']}-{single_sentence_data['end_time']}%%\"\n",
    "\n",
    "\n",
    "            # sign_embeddings = torch.clone(video_embeddings[ single_sentence_data['start_time']*10 : (single_sentence_data['end_time']+1)*10 ])\n",
    "\n",
    "            sign_array_of_single_sentence = []\n",
    "\n",
    "            skeletons_of_single_sentence = single_sentence_data['skeletons']\n",
    "\n",
    "            for single_skeleton in skeletons_of_single_sentence:\n",
    "                single_skeleton_numbers = []\n",
    "                for key_of_skeleton in keys_of_skeleton:\n",
    "                    single_skeleton_numbers.append(single_skeleton[key_of_skeleton])\n",
    "                sign_array_of_single_sentence.append(single_skeleton_numbers)\n",
    "\n",
    "            final_array.append({\n",
    "                \"name\": sequence_id,\n",
    "                \"signer\": irrelevant_const,\n",
    "                \"gloss\": irrelevant_const,\n",
    "                \"sign\": torch.Tensor(sign_array_of_single_sentence),\n",
    "                # \"sign\": sign_embeddings,\n",
    "                \"text\": single_sentence_data['bengali']\n",
    "            })\n",
    "\n",
    "        json_file_object.close()\n",
    "    return final_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1031f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [02:15<00:00,  1.78it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.49it/s]\n",
      "100%|██████████| 14/14 [00:09<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set = generate_final_array(train_set_videos)\n",
    "test_set = generate_final_array(test_set_videos)\n",
    "validation_set = generate_final_array(validation_set_videos)\n",
    "\n",
    "random.shuffle(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060d5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8879\n",
      "562\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372885f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_pickle_handler = open(\"data_for_stochastic/phoenix14t.pami0.train\",\"wb\")\n",
    "validation_array_pickle_handler = open(\"data_for_stochastic/phoenix14t.pami0.dev\",\"wb\")\n",
    "test_array_pickle_handler = open(\"data_for_stochastic/phoenix14t.pami0.test\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0df39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumping train pickles\n",
      "dumping test pickles\n",
      "dumping dev pickles\n"
     ]
    }
   ],
   "source": [
    "print(\"dumping train pickles\")\n",
    "pickle.dump(train_set, train_array_pickle_handler)\n",
    "print(\"dumping test pickles\")\n",
    "pickle.dump(test_set, test_array_pickle_handler)\n",
    "print(\"dumping dev pickles\")\n",
    "pickle.dump(validation_set, validation_array_pickle_handler)\n",
    "\n",
    "train_array_pickle_handler.close()\n",
    "validation_array_pickle_handler.close()\n",
    "test_array_pickle_handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4aca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_video_names_of_set(file_name, list_of_video_names):\n",
    "    text_file = open(file_name,'a', encoding='utf-8')\n",
    "    for name in list_of_video_names:\n",
    "        print(name,file=text_file)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415b0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_video_names_of_set('data_for_stochastic/train_video_names.txt',train_set_videos)\n",
    "print_video_names_of_set('data_for_stochastic/test_video_names.txt',test_set_videos)\n",
    "print_video_names_of_set('data_for_stochastic/validation_video_names.txt',validation_set_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a9477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2948e2135441f7c17828407a457c54d0f2e9d2c96cc787101a5a0573b6a04d73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
