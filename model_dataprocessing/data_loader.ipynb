{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from moviepy.editor import *\n",
    "from moviepy.config import change_settings\n",
    "import os\n",
    "change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\\\Program Files\\\\ImageMagick-7.1.1-Q16-HDRI\\\\magick.exe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number_of_skeletons = 1000\n",
    "number_of_skeletons = None\n",
    "number_of_selected_sentences = 10\n",
    "skeleton_map_path = \"../extractedbtvdataset/skeleton_sentence_map.csv\"\n",
    "sentence_path = \"../extractedbtvdataset/sentences.csv\"\n",
    "\n",
    "class SelectedColumns:\n",
    "    def __init__(self):\n",
    "        selected_points_for_sign = [{\n",
    "            'limb': 'pose',\n",
    "            'points': range(8)\n",
    "        },{\n",
    "            'limb': 'face',\n",
    "            'points': range(48, 68, 1)\n",
    "        },{\n",
    "            'limb': 'hand_right',\n",
    "            'points': range(21)\n",
    "        },{\n",
    "            'limb': 'hand_left',\n",
    "            'points': range(21)\n",
    "        }]\n",
    "\n",
    "        selected_columns = []\n",
    "        for limb in selected_points_for_sign:\n",
    "            limb_name = limb['limb']\n",
    "            for point in limb['points']:\n",
    "                selected_columns.append(f\"{limb_name}_{point}_x\")\n",
    "                selected_columns.append(f\"{limb_name}_{point}_y\")\n",
    "        \n",
    "        self.selected_columns = selected_columns + ['sentence_id', 'frame_index_in_sentence']\n",
    "        self.selected_pose_points = selected_columns\n",
    "    \n",
    "    def check_column(self, column_name):\n",
    "        if not column_name in self.selected_columns:\n",
    "            raise Exception(f\"column {column_name} in dataframe\")\n",
    "    \n",
    "    def keep_columns(self, dataframe):\n",
    "        return dataframe[self.selected_columns]\n",
    "    \n",
    "    def get_selected_columns(self):\n",
    "        return self.selected_columns\n",
    "    \n",
    "    def get_selected_pose_points(self):\n",
    "        return self.selected_pose_points\n",
    "\n",
    "selected_column = SelectedColumns()     \n",
    "\n",
    "class PoseGraph:\n",
    "    def __init__(self) -> None:\n",
    "        self.graph = {\n",
    "            'pose_0': ['face_48','face_54','pose_1'],\n",
    "            'pose_1':['pose_2', 'pose_5'],\n",
    "            'pose_2':['pose_3'],\n",
    "            'pose_3':['pose_4'],\n",
    "            'pose_4':['hand_right_0'],\n",
    "            'pose_5':['pose_6'],\n",
    "            'pose_6':['pose_7'],\n",
    "            'pose_7':['hand_left_0'],\n",
    "            'hand_left_0': [f\"hand_left_{i}\" for i in [1,5,9,13,17]],\n",
    "            'hand_left_1': ['hand_left_2'],\n",
    "            'hand_left_2': ['hand_left_3'],\n",
    "            'hand_left_3': ['hand_left_4'],\n",
    "            'hand_left_4': [],\n",
    "            'hand_left_5': ['hand_left_6'],\n",
    "            'hand_left_6': ['hand_left_7'],\n",
    "            'hand_left_7': ['hand_left_8'],\n",
    "            'hand_left_8': [],\n",
    "            'hand_left_9': ['hand_left_10'],\n",
    "            'hand_left_10': ['hand_left_11'],\n",
    "            'hand_left_11': ['hand_left_12'],\n",
    "            'hand_left_12': [],\n",
    "            'hand_left_13': ['hand_left_14'],\n",
    "            'hand_left_14': ['hand_left_15'],\n",
    "            'hand_left_15': ['hand_left_16'],\n",
    "            'hand_left_16': [],\n",
    "            'hand_left_17': ['hand_left_18'],\n",
    "            'hand_left_18': ['hand_left_19'],\n",
    "            'hand_left_19': ['hand_left_20'],\n",
    "            'hand_left_20': [],\n",
    "            'hand_right_0': [f\"hand_right_{i}\" for i in [1,5,9,13,17]],\n",
    "            'hand_right_1': ['hand_right_2'],\n",
    "            'hand_right_2': ['hand_right_3'],\n",
    "            'hand_right_3': ['hand_right_4'],\n",
    "            'hand_right_4': [],\n",
    "            'hand_right_5': ['hand_right_6'],\n",
    "            'hand_right_6': ['hand_right_7'],\n",
    "            'hand_right_7': ['hand_right_8'],\n",
    "            'hand_right_8': [],\n",
    "            'hand_right_9': ['hand_right_10'],\n",
    "            'hand_right_10': ['hand_right_11'],\n",
    "            'hand_right_11': ['hand_right_12'],\n",
    "            'hand_right_12': [],\n",
    "            'hand_right_13': ['hand_right_14'],\n",
    "            'hand_right_14': ['hand_right_15'],\n",
    "            'hand_right_15': ['hand_right_16'],\n",
    "            'hand_right_16': [],\n",
    "            'hand_right_17': ['hand_right_18'],\n",
    "            'hand_right_18': ['hand_right_19'],\n",
    "            'hand_right_19': ['hand_right_20'],\n",
    "            'hand_right_20': [],\n",
    "            'face_48':['face_49','face_60','face_59'],\n",
    "            'face_49':['face_50'],\n",
    "            'face_50':['face_51'],\n",
    "            'face_51':[],\n",
    "            'face_52':[],\n",
    "            'face_53':['face_52'],\n",
    "            'face_54':['face_53','face_64','face_55'],\n",
    "            'face_55':['face_56'],\n",
    "            'face_56':[],\n",
    "            'face_57':[],\n",
    "            'face_58':['face_57'],\n",
    "            'face_59':['face_58'],\n",
    "            'face_60':['face_61','face_67'],\n",
    "            'face_61':['face_62'],\n",
    "            'face_62':[],\n",
    "            'face_63':[],\n",
    "            'face_64':['face_63','face_65'],\n",
    "            'face_65':[],\n",
    "            'face_66':[],\n",
    "            'face_67':['face_66']\n",
    "        }\n",
    "\n",
    "        self.parents = {}\n",
    "        self.BFS()\n",
    "    def BFS(self):\n",
    "        self.bfs_traversal = []\n",
    "        visited = set()\n",
    "        queue = deque(['pose_0'])\n",
    "        while queue:\n",
    "            vertex = queue.popleft()\n",
    "            self.bfs_traversal.append(vertex)\n",
    "            if vertex not in visited:\n",
    "                visited.add(vertex)\n",
    "                for neighbor in self.graph[vertex]:\n",
    "                    if neighbor not in visited:\n",
    "                        self.parents[neighbor] = vertex\n",
    "                        queue.extend([neighbor])\n",
    "\n",
    "    def get_bfs_traversal(self):\n",
    "        return self.bfs_traversal\n",
    "    \n",
    "    def get_parent_of_point(self, keypoint):\n",
    "        return self.parents[keypoint]\n",
    "    \n",
    "graph = PoseGraph()\n",
    "\n",
    "\n",
    "class SentenceData:\n",
    "    def __init__(self, id, dataframe, start_time, end_time, video_name, sentence) -> None:\n",
    "        self.id = id\n",
    "        self.dataframe = dataframe.set_index('frame_index_in_sentence')\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.video_name = video_name\n",
    "        self.sentence = sentence\n",
    "\n",
    "    def get(self, index, point_name):\n",
    "        selected_column.check_column(point_name)\n",
    "        return self.dataframe.loc[index,point_name]\n",
    "    \n",
    "    def set(self, index, point_name, value) -> None:\n",
    "        selected_column.check_column(point_name)\n",
    "        self.dataframe.loc[index,point_name] = value\n",
    "\n",
    "    def get_row_count(self):\n",
    "        return self.dataframe.shape[0]\n",
    "    \n",
    "    def print(self):\n",
    "        print(self.dataframe.head())\n",
    "        print(f\"columns: {self.dataframe.columns}\")\n",
    "        print(f\"row count: {self.dataframe.shape[0]}\")\n",
    "\n",
    "    def estimate_point_from_previous_time(self, time, column_name):\n",
    "        if time == 0 or time >= self.get_row_count():\n",
    "            raise Exception(\"ERROR\")\n",
    "        x_or_y = column_name.split(\"_\")[-1]\n",
    "        point_name = \"_\".join(column_name.split(\"_\")[:-1])\n",
    "        parent_point = graph.get_parent_of_point(point_name)\n",
    "        parent_of_current_time= self.get(time, point_name=parent_point+f\"_{x_or_y}\")\n",
    "        parent_of_previous_time = self.get(time-1, point_name=parent_point+f\"_{x_or_y}\")\n",
    "        point_of_previous_time = self.get(time-1, point_name=column_name)\n",
    "        if parent_of_current_time == 0 or parent_of_previous_time == 0 or point_of_previous_time == 0:\n",
    "            return 0\n",
    "        \n",
    "        return round(point_of_previous_time + (parent_of_current_time - parent_of_previous_time),3)\n",
    "    \n",
    "    def estimate_point_from_next_time(self, time, column_name):\n",
    "        if time >= self.get_row_count() - 1:\n",
    "            raise Exception(\"ERROR\")\n",
    "        x_or_y = column_name.split(\"_\")[-1]\n",
    "        point_name = \"_\".join(column_name.split(\"_\")[:-1])\n",
    "        parent_point = graph.get_parent_of_point(point_name)\n",
    "        parent_of_current_time= self.get(time, point_name=parent_point+f\"_{x_or_y}\")\n",
    "        parent_of_next_time = self.get(time+1, point_name=parent_point+f\"_{x_or_y}\")\n",
    "        point_of_next_time = self.get(time+1, point_name=column_name)\n",
    "        if parent_of_current_time == 0 or parent_of_next_time == 0 or point_of_next_time == 0:\n",
    "            return 0\n",
    "        \n",
    "        return round(point_of_next_time + (parent_of_current_time - parent_of_next_time),3)\n",
    "    \n",
    "    def get_missing_value_count(self):\n",
    "        return (self.dataframe == 0).sum().sum()\n",
    "    \n",
    "    def replace_missing_value_from_previous_time(self):\n",
    "        for i in range(1, self.get_row_count()):\n",
    "            for point_name in graph.get_bfs_traversal():\n",
    "                column_name_x = f\"{point_name}_x\"\n",
    "                column_name_y = f\"{point_name}_y\"\n",
    "                if self.get(i, column_name_x) == 0:\n",
    "                    self.set(i, column_name_x, self.estimate_point_from_previous_time(i, column_name=column_name_x))\n",
    "                if self.get(i, column_name_y) == 0:\n",
    "                    self.set(i, column_name_y, self.estimate_point_from_previous_time(i, column_name=column_name_y))\n",
    "\n",
    "    def replace_missing_value_from_next_time(self):\n",
    "        for i in range(self.get_row_count()-2, -1, -1):\n",
    "            for point_name in graph.get_bfs_traversal():\n",
    "                column_name_x = f\"{point_name}_x\"\n",
    "                column_name_y = f\"{point_name}_y\"\n",
    "                if self.get(i, column_name_x) == 0:\n",
    "                    self.set(i, column_name_x, self.estimate_point_from_next_time(i, column_name=column_name_x))\n",
    "                if self.get(i, column_name_y) == 0:\n",
    "                    self.set(i, column_name_y, self.estimate_point_from_next_time(i, column_name=column_name_y))\n",
    "\n",
    "    def render_skeleton_sentence_map():\n",
    "        \n",
    "\n",
    "class SignLanguageDataset:\n",
    "    def __init__(self) -> None:\n",
    "        print(\"reading csv from file...\")\n",
    "        self.dataframe = pd.read_csv(skeleton_map_path, nrows = number_of_skeletons, index_col=0)\n",
    "        sentence_ids = self.dataframe['sentence_id'].unique()\n",
    "        print(\"splitting unique sentences...\")\n",
    "        self.sentences = []\n",
    "\n",
    "        self.sentence_dataframe = pd.read_csv(sentence_path)\n",
    "\n",
    "        for id in tqdm(sentence_ids[:number_of_selected_sentences]):\n",
    "            sentence_dataframe = self.dataframe[self.dataframe['sentence_id'] == id]\n",
    "            sentence_info = self.get_sentence_info_by_id(id)\n",
    "            start_time = float(sentence_info['start_time'])\n",
    "            end_time = float(sentence_info['end_time'])\n",
    "            sentence = sentence_info['sentence'].iloc[0]\n",
    "            video_name = sentence_info['video_name'].iloc[0]\n",
    "            self.sentences.append(SentenceData(id, sentence_dataframe, start_time=start_time, end_time=end_time, video_name=video_name, sentence=sentence))\n",
    "\n",
    "        self.column_names = self.dataframe.columns\n",
    "    \n",
    "    def get(self, index):\n",
    "        return self.sentences[index]\n",
    "    \n",
    "    def get_sentence_info_by_id(self, id):\n",
    "        return self.sentence_dataframe[self.sentence_dataframe[\"sentence_id\"] == id].reset_index()\n",
    "    \n",
    "    def get_sentence_count(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def get_column_names(self):\n",
    "        return self.column_names\n",
    "    \n",
    "    def replace_all_missing_data_using_previous_time(self):\n",
    "        for i in tqdm(range(self.get_sentence_count())):\n",
    "            self.sentences[i].replace_missing_value_from_previous_time()\n",
    "    \n",
    "    def replace_all_missing_data_using_next_time(self):\n",
    "        for i in tqdm(range(self.get_sentence_count())):\n",
    "            self.sentences[i].replace_missing_value_from_next_time()\n",
    "\n",
    "\n",
    "    def get_total_missing_value(self):\n",
    "        total_missing = 0\n",
    "        for i in tqdm(range(self.get_sentence_count())):\n",
    "            total_missing = total_missing + self.sentences[i].get_missing_value_count()\n",
    "\n",
    "        return total_missing\n",
    "\n",
    "    def save_csv(self):\n",
    "        combined_dataframe = pd.DataFrame()\n",
    "        for i in tqdm(range(self.get_sentence_count())):\n",
    "            sentence_dataframe = self.sentences[i].dataframe.reset_index()\n",
    "            combined_dataframe = pd.concat([combined_dataframe, sentence_dataframe], axis=0)\n",
    "        combined_dataframe.reset_index(inplace=True)\n",
    "        combined_dataframe.drop(['index'], axis=1, inplace=True)\n",
    "        combined_dataframe.to_csv('implemented_algorithm.csv')\n",
    "        combined_dataframe.head(100).to_csv('implemented_algorithm_snapshot.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading csv from file...\n",
      "splitting unique sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.87it/s]\n"
     ]
    }
   ],
   "source": [
    "sign_data = SignLanguageDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 588.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27848"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_data.get_total_missing_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "sign_data.replace_all_missing_data_using_next_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sign_data.replace_all_missing_data_using_previous_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 588.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18802"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_data.get_total_missing_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "এই ছিল এখনকার আয়োজনে\n",
      "823.0697\n",
      "824.9697\n",
      "_u6jEqimZdc\n",
      "বেসরকারি বিমান পরিবহন ও পর্যটন মন্ত্রণালয় সম্পর্কিত সংসদীয় স্থায়ী কমিটির সভাপতি আ ম উবায়দুল মোকতাদির চৌধুরী বিজয়ীদের মাঝে পুরস্কার বিতরণ করেন\n",
      "808.9453\n",
      "819.8453\n",
      "_u6jEqimZdc\n"
     ]
    }
   ],
   "source": [
    "print(sign_data.get(4).sentence)\n",
    "print(sign_data.get(4).start_time)\n",
    "print(sign_data.get(4).end_time)\n",
    "print(sign_data.get(4).video_name)\n",
    "\n",
    "print(sign_data.get(5).sentence)\n",
    "print(sign_data.get(5).start_time)\n",
    "print(sign_data.get(5).end_time)\n",
    "print(sign_data.get(5).video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 475.63it/s]\n"
     ]
    }
   ],
   "source": [
    "sign_data.save_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
